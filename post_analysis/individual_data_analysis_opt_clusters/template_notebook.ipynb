{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Import libraries\n",
        "import scanpy as sc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from scipy.sparse import issparse\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "from sklearn import metrics\n",
        "from scipy import stats\n",
        "import warnings\n",
        "import sys\n",
        "\n",
        "\n",
        "# Set plotting settings\n",
        "sc.settings.verbosity = 3\n",
        "sc.settings.set_figure_params(dpi=100, frameon=False)\n",
        "\n",
        "BASE_DIR = \"/beegfs/scratch/ric.broccoli/kubacki.michal/SRF_Linda_RNA/\""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "samples = {\n",
        "    \"Emx1_Ctrl\": \"cellranger_counts_R26_Emx1_Ctrl_adult_0\",\n",
        "    \"Emx1_Mut\": \"cellranger_counts_R26_Emx1_Mut_adult_1\",\n",
        "    \"Nestin_Ctrl\": \"cellranger_counts_R26_Nestin_Ctrl_adult_2\",\n",
        "    \"Nestin_Mut\": \"cellranger_counts_R26_Nestin_Mut_adult_3\"\n",
        "    }"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# This cell will be parameterized by the script\n",
        "SAMPLE_NAME = \"SAMPLE_PLACEHOLDER\"  # This will be replaced with the actual sample name\n",
        "# SAMPLE_NAME = \"Emx1_Ctrl\"\n",
        "print(f\"Processing sample: {SAMPLE_NAME}\")\n",
        "\n",
        "# %% [markdown]\n",
        "# # 1. Setup and Data Loading"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "SAMPLE = samples[SAMPLE_NAME]\n",
        "\n",
        "WORKING_DIR = os.path.join(BASE_DIR, \"post_analysis\", \"individual_data_analysis_opt_clusters\", SAMPLE)\n",
        "os.makedirs(WORKING_DIR, exist_ok=True)\n",
        "\n",
        "CELL_DATA_DIR = \"cellranger_final_count_data\"\n",
        "matrix_dir = os.path.join(BASE_DIR, CELL_DATA_DIR, SAMPLE, \"outs\", \"filtered_feature_bc_matrix\")\n",
        "\n",
        "os.chdir(WORKING_DIR)\n",
        "OUTPUT_DIR=WORKING_DIR\n",
        "\n",
        "sys.path.append(os.path.join(BASE_DIR, \"post_analysis\", \"individual_data_analysis_opt_clusters\"))\n",
        "from functions import *\n",
        "\n",
        "# Load the data from the filtered matrix\n",
        "try:\n",
        "    adata = sc.read_10x_mtx(\n",
        "        matrix_dir,\n",
        "        var_names='gene_symbols',\n",
        "        cache=True\n",
        "    )\n",
        "    print(f\"Shape of loaded data: {adata.shape}\")  # cells \u00d7 genes\n",
        "except ValueError as e:\n",
        "    print(f\"Error loading data: {e}\")\n",
        "    # Try loading with different parameters to handle the mismatch\n",
        "    adata = sc.read_10x_mtx(\n",
        "        matrix_dir,\n",
        "        var_names='gene_symbols',\n",
        "        cache=False\n",
        "    )\n",
        "    print(f\"Shape of loaded data after retry: {adata.shape}\")  # cells \u00d7 genes\n",
        "\n",
        "# %% [markdown]\n",
        "# # 2. Basic Pre-processing"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Make a copy of the raw counts\n",
        "adata.raw = adata.copy()\n",
        "\n",
        "# Basic filtering\n",
        "sc.pp.filter_cells(adata, min_genes=200)\n",
        "sc.pp.filter_genes(adata, min_cells=3)\n",
        "\n",
        "# Calculate QC metrics\n",
        "adata.var['mt'] = adata.var_names.str.startswith('mt-')  # identify mitochondrial genes\n",
        "sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True)\n",
        "\n",
        "# Plot QC metrics\n",
        "fig, axs = plt.subplots(1, 3, figsize=(15, 4))\n",
        "sns.histplot(adata.obs['n_genes_by_counts'], kde=False, ax=axs[0])\n",
        "axs[0].set_title('Genes per cell')\n",
        "sns.histplot(adata.obs['total_counts'], kde=False, ax=axs[1])\n",
        "axs[1].set_title('UMI counts per cell')\n",
        "sns.histplot(adata.obs['pct_counts_mt'], kde=False, ax=axs[2])\n",
        "axs[2].set_title('Percent mitochondrial')\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save the plot to the output directory\n",
        "plt.savefig(os.path.join(OUTPUT_DIR, 'qc_metrics.png'))\n",
        "plt.show()\n",
        "\n",
        "# %% [markdown]\n",
        "# # 3. Filtering Based on QC Metrics"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "max_genes = 15000 \n",
        "min_genes = 500  \n",
        "max_mt_pct = 20  \n",
        "\n",
        "adata = adata[adata.obs['n_genes_by_counts'] < max_genes, :]\n",
        "adata = adata[adata.obs['n_genes_by_counts'] > min_genes, :]\n",
        "adata = adata[adata.obs['pct_counts_mt'] < max_mt_pct, :]\n",
        "\n",
        "print(f\"Number of cells after filtering: {adata.n_obs}\")\n",
        "print(f\"Number of genes after filtering: {adata.n_vars}\")\n",
        "\n",
        "# %% [markdown]\n",
        "# # 4. Normalization and Log Transformation"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Normalize to 10,000 reads per cell\n",
        "sc.pp.normalize_total(adata, target_sum=1e4)\n",
        "\n",
        "# Log transform\n",
        "sc.pp.log1p(adata)\n",
        "\n",
        "# Identify highly variable genes\n",
        "sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5)\n",
        "print(f\"Number of highly variable genes: {sum(adata.var.highly_variable)}\")\n",
        "\n",
        "# Plot highly variable genes\n",
        "plt.figure(figsize=(10, 8))\n",
        "sc.pl.highly_variable_genes(adata, show=False)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Save the current normalized and log-transformed data to a new layer BEFORE scaling\n",
        "adata.layers['for_cell_typist'] = adata.X.copy()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Quick check that the data in the layer is correctly normalized\n",
        "# Reverse log1p transformation\n",
        "if issparse(adata.layers['for_cell_typist']):\n",
        "    counts_in_layer = adata.layers['for_cell_typist'].copy()\n",
        "    counts_in_layer.data = np.expm1(counts_in_layer.data)\n",
        "else:\n",
        "    counts_in_layer = np.expm1(adata.layers['for_cell_typist'])\n",
        "\n",
        "# Sum counts per cell\n",
        "total_counts_layer = np.asarray(counts_in_layer.sum(axis=1)).flatten()\n",
        "\n",
        "print(\"\\nVerifying normalization in 'for_cell_typist' layer:\")\n",
        "print(f\"  Mean total counts (reversed log1p): {total_counts_layer.mean():.2f}\")\n",
        "print(f\"  Median total counts (reversed log1p): {np.median(total_counts_layer):.2f}\")\n",
        "\n",
        "# Basic QC check for the layer\n",
        "if np.mean(total_counts_layer) < 9900 or np.mean(total_counts_layer) > 10100:\n",
        "    warnings.warn(f\"Normalization in 'for_cell_typist' layer may not be exactly 10k (Mean: {total_counts_layer.mean():.2f}). Check normalization step.\")\n",
        "else:\n",
        "    print(\"  Normalization in 'for_cell_typist' layer appears correct (around 10k).\")\n",
        "\n",
        "# %% [markdown]\n",
        "# # 5. Dimensionality Reduction"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Scale adata.X to unit variance and zero mean AFTER saving the normalized layer\n",
        "# This step modifies adata.X but leaves adata.layers['for_cell_typist'] untouched\n",
        "sc.pp.scale(adata, max_value=10)\n",
        "\n",
        "# Run PCA\n",
        "sc.tl.pca(adata, svd_solver='arpack')\n",
        "\n",
        "# Determine number of significant PCs\n",
        "sc.pl.pca_variance_ratio(adata, n_pcs=50, log=True)\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Choose number of PCs for downstream analyses\n",
        "n_pcs = 30  # Adjust based on the variance ratio plot\n",
        "\n",
        "# Compute neighborhood graph\n",
        "sc.pp.neighbors(adata, n_neighbors=15, n_pcs=n_pcs)\n",
        "\n",
        "# Run UMAP\n",
        "sc.tl.umap(adata)\n",
        "\n",
        "# Plot UMAP\n",
        "plt.figure(figsize=(10, 8))\n",
        "sc.pl.umap(adata, color=['total_counts', 'n_genes_by_counts', 'pct_counts_mt'], \n",
        "        use_raw=False, color_map='viridis', show=False)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# %% [markdown]\n",
        "# # 6. Marker Gene Identification"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Try different resolutions to find optimal number of clusters\n",
        "resolution_range=[0.05, 0.8]\n",
        "n_resolutions=10\n",
        "resolutions = np.linspace(resolution_range[0], resolution_range[1], n_resolutions)\n",
        "resolutions = [round(r, 2) for r in resolutions]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Check first 5 values from first cell\n",
        "if issparse(adata.X):\n",
        "    print(\"X matrix values (first cell):\", adata.X[0, :5].toarray().flatten())\n",
        "else:\n",
        "    print(\"X matrix values (first cell):\", adata.X[0, :5])\n",
        "print(\"Should be log1p transformed values (~0-5 range)\")\n",
        "\n",
        "# Check raw values if raw exists\n",
        "if adata.raw:\n",
        "    if issparse(adata.raw.X):\n",
        "        print(\"Raw values:\", adata.raw.X[0, :5].toarray().flatten())\n",
        "    else:\n",
        "        print(\"Raw values:\", adata.raw.X[0, :5])\n",
        "    print(\"Should be original counts (integers)\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# With custom parameters\n",
        "optimal_resolution = analyze_and_select_best_clustering(\n",
        "    adata,\n",
        "    resolutions=resolutions,\n",
        "    run_marker_analysis=True,       # Run marker gene analysis\n",
        "    leiden_key='leiden',            # Base name for cluster labels\n",
        "    output_dir=\"my_cluster_analysis\"  # Output directory\n",
        ")\n",
        "\n",
        "# Annotate adata with optimal clustering (if not already present)\n",
        "best_clustering = f\"leiden_{optimal_resolution}\"\n",
        "if best_clustering not in adata.obs:\n",
        "    sc.tl.leiden(adata, resolution=optimal_resolution, key_added=best_clustering)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load the CSV file\n",
        "df = pd.read_csv(os.path.join(OUTPUT_DIR, 'my_cluster_analysis', 'evaluation', 'clustering_quality_metrics.csv'))\n",
        "\n",
        "# Sort the dataframe by overall_score in descending order\n",
        "sorted_df = df.sort_values(by='overall_score', ascending=False)\n",
        "\n",
        "# Create an ordered list of resolutions\n",
        "ordered_resolutions = sorted_df['resolution'].tolist()\n",
        "scores = []\n",
        "print(\"Resolutions ordered by overall_score (highest to lowest):\")\n",
        "for i, res in enumerate(ordered_resolutions, 1):\n",
        "    score = sorted_df.loc[sorted_df['resolution'] == res, 'overall_score'].values[0]\n",
        "    scores.append(score)\n",
        "    print(f\"{i}. Resolution: {res}, Overall Score: {score}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Try different resolutions to find optimal number of clusters\n",
        "best_resolutions = ordered_resolutions[:3]\n",
        "print(best_resolutions)\n",
        "# Plot clusters at different resolutions with improved layout\n",
        "fig, axes = plt.subplots(1, len(best_resolutions), figsize=(20, 5))\n",
        "for i, res in enumerate(best_resolutions):\n",
        "    sc.pl.umap(adata, color=f'leiden_{res}', title=f'Resolution {res}, score {scores[i]}', \n",
        "               frameon=True, legend_loc='on data', legend_fontsize=10, ax=axes[i], show=False)\n",
        "\n",
        "# Ensure proper spacing between subplots\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# %% [markdown]\n",
        "# # 7. Save Processed Data"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Define the output file path\n",
        "output_adata_file = os.path.join(OUTPUT_DIR, f\"{SAMPLE_NAME}_processed.h5ad\")\n",
        "\n",
        "# List all clustering assignments stored in the adata object\n",
        "print(\"Clustering assignments stored in the AnnData object:\")\n",
        "leiden_columns = [col for col in adata.obs.columns if col.startswith('leiden_')]\n",
        "for col in leiden_columns:\n",
        "    n_clusters = len(adata.obs[col].unique())\n",
        "    print(f\"  - {col}: {n_clusters} clusters\")\n",
        "\n",
        "# Save the AnnData object with all clustering results\n",
        "print(f\"\\nSaving processed AnnData object to: {output_adata_file}\")\n",
        "try:\n",
        "    adata.write(output_adata_file)\n",
        "    print(\"Successfully saved AnnData object with all clustering assignments.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving AnnData object: {e}\")\n",
        "\n",
        "# %% [markdown]\n",
        "# # 8. Visualize Clustering Results and Quality Metrics"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Display the optimal clustering on UMAP\n",
        "plt.figure(figsize=(12, 10))\n",
        "sc.pl.umap(adata, color=f'leiden_{optimal_resolution}', \n",
        "           title=f'Optimal Clustering (Resolution={optimal_resolution})', \n",
        "           legend_loc='on data', frameon=True, show=False)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUT_DIR, 'optimal_clustering_umap.png'), dpi=150)\n",
        "plt.show()\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 8.1 Clustering Quality Metrics Analysis"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load the clustering quality metrics\n",
        "metrics_df = pd.read_csv(os.path.join(OUTPUT_DIR, 'my_cluster_analysis', 'evaluation', 'clustering_quality_metrics.csv'))\n",
        "print(\"Clustering quality metrics summary:\")\n",
        "display(metrics_df[['resolution', 'n_clusters', 'silhouette_score', 'davies_bouldin_score', 'marker_gene_score', 'overall_score']])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Display the main clustering quality metrics visualization\n",
        "from IPython.display import Image, display\n",
        "\n",
        "print(\"Clustering quality metrics across resolutions:\")\n",
        "metrics_img = Image(os.path.join(OUTPUT_DIR, 'my_cluster_analysis', 'evaluation', 'clustering_quality_metrics.png'))\n",
        "display(metrics_img)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Display metric contributions visualization if available\n",
        "metric_details_path = os.path.join(OUTPUT_DIR, 'my_cluster_analysis', 'evaluation', 'metric_details')\n",
        "if os.path.exists(metric_details_path):\n",
        "    contributions_img = Image(os.path.join(metric_details_path, 'metric_contributions.png'))\n",
        "    print(\"Contribution of each metric to the overall score:\")\n",
        "    display(contributions_img)\n",
        "    \n",
        "    individual_metrics_img = Image(os.path.join(metric_details_path, 'individual_metrics.png'))\n",
        "    print(\"Individual metrics across resolutions:\")\n",
        "    display(individual_metrics_img)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load and display the metric contribution summary\n",
        "contribution_summary_path = os.path.join(OUTPUT_DIR, 'my_cluster_analysis', 'evaluation', 'metric_details', 'metric_contribution_summary.csv')\n",
        "if os.path.exists(contribution_summary_path):\n",
        "    contribution_df = pd.read_csv(contribution_summary_path)\n",
        "    print(\"Metric contribution summary:\")\n",
        "    display(contribution_df)\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 8.2 Marker Genes for Optimal Clustering"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Display marker heatmap for optimal clustering\n",
        "optimal_heatmap_path = os.path.join(OUTPUT_DIR, 'my_cluster_analysis', 'evaluation', 'optimal_clustering_heatmap.png')\n",
        "if os.path.exists(optimal_heatmap_path):\n",
        "    # Instead of just displaying the image, let's create an improved version\n",
        "    # First, get the marker genes and expression data\n",
        "    leiden_key = f'leiden_{optimal_resolution}'\n",
        "    \n",
        "    # Check if we have marker genes information\n",
        "    if f\"rank_genes_{optimal_resolution}\" in adata.uns:\n",
        "        # Get top markers for each cluster (adjust n_genes as needed)\n",
        "        n_top_genes = 20\n",
        "        sc.tl.dendrogram(adata, groupby=leiden_key)\n",
        "        \n",
        "        # Create an improved heatmap with better formatting\n",
        "        plt.figure(figsize=(14, 10))\n",
        "        sc.pl.heatmap(adata, var_names=adata.uns[f'rank_genes_{optimal_resolution}']['names'][:n_top_genes], \n",
        "                      groupby=leiden_key, \n",
        "                      swap_axes=True,              # Put genes on y-axis for better labels\n",
        "                      show_gene_labels=True,       # Show gene names\n",
        "                      dendrogram=True,             # Show the dendrogram\n",
        "                      cmap='viridis',              # Use a perceptually uniform colormap\n",
        "                      vmin=0, vmax=None,           # Set minimum value to 0\n",
        "                      standard_scale='var',        # Scale expression by gene\n",
        "                      use_raw=True,                # Use raw counts for better contrast\n",
        "                      show=False)\n",
        "        \n",
        "        plt.title(f\"Top Markers for Optimal Clustering (Resolution={optimal_resolution})\", fontsize=16)\n",
        "        plt.tight_layout()\n",
        "        \n",
        "        # Save the improved heatmap\n",
        "        improved_heatmap_path = os.path.join(OUTPUT_DIR, 'my_cluster_analysis', 'evaluation', 'improved_clustering_heatmap.png')\n",
        "        plt.savefig(improved_heatmap_path, dpi=150, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        \n",
        "        print(f\"Improved marker gene heatmap saved to: {improved_heatmap_path}\")\n",
        "    else:\n",
        "        # If we don't have marker genes, display the original heatmap\n",
        "        optimal_heatmap_img = Image(optimal_heatmap_path)\n",
        "        print(f\"Marker gene heatmap for optimal clustering (resolution={optimal_resolution}):\")\n",
        "        display(optimal_heatmap_img)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load and display top markers for each cluster in the optimal clustering\n",
        "markers_file = os.path.join(OUTPUT_DIR, 'my_cluster_analysis', 'marker_analysis', f'cluster_markers_res{optimal_resolution}.csv')\n",
        "if os.path.exists(markers_file):\n",
        "    markers_df = pd.read_csv(markers_file)\n",
        "    \n",
        "    # Create a more readable format for marker genes by cluster\n",
        "    top_markers_by_cluster = {}\n",
        "    for cluster in sorted(markers_df['cluster'].unique()):\n",
        "        cluster_markers = markers_df[markers_df['cluster'] == cluster].sort_values('pvals_adj').head(10)\n",
        "        top_markers_by_cluster[cluster] = list(zip(\n",
        "            cluster_markers['names'], \n",
        "            cluster_markers['logfoldchanges'].round(2),\n",
        "            cluster_markers['pvals_adj'].apply(lambda x: f\"{x:.2e}\")\n",
        "        ))\n",
        "    \n",
        "    # Display top markers for each cluster\n",
        "    print(f\"Top marker genes for each cluster at resolution {optimal_resolution}:\")\n",
        "    for cluster, markers in top_markers_by_cluster.items():\n",
        "        print(f\"\\nCluster {cluster}:\")\n",
        "        for i, (gene, lfc, pval) in enumerate(markers, 1):\n",
        "            print(f\"  {i}. {gene} (log2FC: {lfc}, adj.p-val: {pval})\")\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 8.3 Resolution Comparison Summary"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load the resolution comparison summary\n",
        "summary_file = os.path.join(OUTPUT_DIR, 'my_cluster_analysis', 'marker_analysis', 'resolution_comparison_summary.csv')\n",
        "if os.path.exists(summary_file):\n",
        "    summary_df = pd.read_csv(summary_file)\n",
        "    print(\"Resolution comparison summary:\")\n",
        "    display(summary_df)\n",
        "    \n",
        "    # Plot resolution comparison metrics\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    \n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.bar(summary_df['Resolution'].astype(str), summary_df['Clusters'])\n",
        "    plt.xlabel('Resolution')\n",
        "    plt.ylabel('Number of clusters')\n",
        "    plt.title('Clusters by resolution')\n",
        "    \n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.bar(summary_df['Resolution'].astype(str), summary_df['Avg_markers_per_cluster'])\n",
        "    plt.xlabel('Resolution')\n",
        "    plt.ylabel('Avg. significant markers per cluster')\n",
        "    plt.title('Marker genes by resolution')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 8.4 Interactive Visualization of Optimal Clustering"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create an interactive visualization of the optimal clustering with marker genes\n",
        "leiden_key = f'leiden_{optimal_resolution}'\n",
        "\n",
        "# Plot UMAP with interactive cluster selection\n",
        "sc.pl.umap(adata, color=leiden_key, legend_loc='on data', \n",
        "           title=f'Interactive UMAP (resolution={optimal_resolution})', \n",
        "           frameon=True, return_fig=True)\n",
        "\n",
        "# Create an interactive panel to explore top markers for each cluster\n",
        "try:\n",
        "    # Only import panel libraries if needed to avoid dependencies\n",
        "    import panel as pn\n",
        "    pn.extension()\n",
        "    \n",
        "    # Get unique clusters\n",
        "    clusters = sorted(adata.obs[leiden_key].unique().astype(str).tolist())\n",
        "    \n",
        "    # Create widgets\n",
        "    cluster_selector = pn.widgets.Select(name='Select Cluster', options=clusters)\n",
        "    n_genes_slider = pn.widgets.IntSlider(name='Number of Genes', start=5, end=20, value=10)\n",
        "    \n",
        "    @pn.depends(cluster_selector.param.value, n_genes_slider.param.value)\n",
        "    def get_marker_table(cluster, n_genes):\n",
        "        # Get markers for selected cluster\n",
        "        if f\"rank_genes_{optimal_resolution}\" in adata.uns:\n",
        "            markers_df = sc.get.rank_genes_groups_df(adata, group=cluster, \n",
        "                                                    key=f\"rank_genes_{optimal_resolution}\")\n",
        "            markers_df = markers_df.head(n_genes)\n",
        "            return pn.pane.DataFrame(markers_df[['names', 'logfoldchanges', 'pvals_adj']], \n",
        "                                     width=600, height=400)\n",
        "        else:\n",
        "            return pn.pane.Markdown(\"Marker gene information not available\")\n",
        "    \n",
        "    # Create layout\n",
        "    marker_panel = pn.Column(\n",
        "        pn.pane.Markdown(f\"# Marker Genes Explorer for Resolution {optimal_resolution}\"),\n",
        "        pn.Row(cluster_selector, n_genes_slider),\n",
        "        get_marker_table\n",
        "    )\n",
        "    \n",
        "    # Display panel\n",
        "    display(marker_panel)\n",
        "except ImportError:\n",
        "    print(\"Panel library not available. Install with 'pip install panel' for interactive visualizations.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error creating interactive visualization: {e}\")\n",
        "\n",
        "# %% [markdown]\n",
        "# # 9. Summary and Conclusion"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load and display the analysis summary\n",
        "summary_path = os.path.join(OUTPUT_DIR, 'my_cluster_analysis', 'analysis_summary.txt')\n",
        "if os.path.exists(summary_path):\n",
        "    with open(summary_path, 'r') as f:\n",
        "        summary_text = f.read()\n",
        "    \n",
        "    from IPython.display import Markdown\n",
        "    display(Markdown(f\"```\\n{summary_text}\\n```\"))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Print final summary\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(f\"CLUSTERING ANALYSIS COMPLETED\")\n",
        "print(f\"{'='*50}\")\n",
        "print(f\"Sample: {SAMPLE_NAME}\")\n",
        "print(f\"Optimal resolution: {optimal_resolution}\")\n",
        "print(f\"Number of clusters: {len(adata.obs[f'leiden_{optimal_resolution}'].unique())}\")\n",
        "print(f\"Total cells analyzed: {adata.n_obs}\")\n",
        "print(f\"Results saved to: {os.path.abspath(OUTPUT_DIR)}\")\n",
        "print(f\"{'='*50}\")\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}